{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from lib.utils import BASE_DIR,SHEETS_DIR,SHEETS_OUTCOMES_DIR,OUTCOME_TABLE_SOURCE_DIR\n",
    "\n",
    "os.makedirs( f\"{OUTCOME_TABLE_SOURCE_DIR}\", exist_ok=True)\n",
    "file_list = glob.glob(f\"{SHEETS_OUTCOMES_DIR}/*編集用/別表-*.csv\")\n",
    "for file in file_list:\n",
    "    name = re.search(r\"別表\\-(.+)\\.csv\",file).group(1)\n",
    "    df = pd.read_csv(file,encoding=\"utf_8_sig\")\n",
    "    df.to_csv(f\"{OUTCOME_TABLE_SOURCE_DIR}/{name}.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "    print(f\"output... {OUTCOME_TABLE_SOURCE_DIR}/{name}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from lib.utils import BASE_DIR,SHEETS_GENERAL_DIR,SHEETS_OUTCOMES_DIR,OUTPUT_DIR,OUTCOME_TABLE_SOURCE_DIR,TABLE_FORMATTED_DIR\n",
    "from lib.apply_condition_to_dataframe  import apply_condition_to_dataframe\n",
    "\n",
    "os.makedirs(OUTPUT_DIR,exist_ok=True)\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{SHEETS_GENERAL_DIR}/略語集/略語.csv\",encoding=\"utf_8_sig\")\n",
    "df.to_csv(f\"{OUTPUT_DIR}/definitions.csv\",encoding=\"utf_8_sig\",index=False)\n",
    "print(f\"output... definitions.csv\")\n",
    "\n",
    "df = pd.read_csv(f\"{SHEETS_OUTCOMES_DIR}/別表一覧/別表一覧.csv\",encoding=\"utf_8_sig\")\n",
    "df.to_csv(f\"{OUTPUT_DIR}/table_index.csv\",encoding=\"utf_8_sig\",index=False)\n",
    "print(f\"output... table_index.csv\")\n",
    "\n",
    "\n",
    "os.makedirs(TABLE_FORMATTED_DIR,exist_ok=True)\n",
    "for row in df.itertuples():\n",
    "    source = pd.read_csv(f\"{OUTCOME_TABLE_SOURCE_DIR}/{row.データ元}.csv\")\n",
    "    source = apply_condition_to_dataframe(source,row.条件)\n",
    "    source[\"index\"]=source.reset_index().index+1\n",
    "    source[\"index\"]=f\"TBL-{row.id}-\"+source[\"index\"].astype(str).str.zfill(3)\n",
    "    source = source\\\n",
    "        .loc[:,[*re.split(r\" *, *\",row.列),\"index\",\"UID\",\"H28対応項目\"] ]\\\n",
    "        .rename(columns={\"H28対応項目\":\"H28ID\"})\n",
    "    source.to_csv(f\"{TABLE_FORMATTED_DIR}/{row.id}.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "from lib.utils import BASE_DIR,SHEETS_OUTCOMES_DIR,OUTPUT_DIR\n",
    "from lib.dataframe_to_grouped_numbers import dataframe_to_grouped_numbers\n",
    "\n",
    "def get_glob_file(glob_path:str)->str:\n",
    "    files = glob.glob(glob_path)\n",
    "    if len(files)==0:\n",
    "        raise Exception(f\"Cannot find {glob_path}\")\n",
    "    return list(glob.glob(glob_path))[0]\n",
    "\n",
    "os.makedirs(f\"{OUTPUT_DIR}\",exist_ok=True)\n",
    "\n",
    "\n",
    "# reading layer 1\n",
    "r4_l1=pd.read_csv(f\"{SHEETS_OUTCOMES_DIR}/第1層/第1層.csv\")\n",
    "r4_l1=r4_l1.rename(columns={\"第1層イニシャル\":\"l1_index\",\"第1層フルスペル\":\"l1_spell\",\"第1層\":\"l1\",\"第1層説明\":\"l1_desc\"})\n",
    "r4_l1=r4_l1.loc[:,[\"l1_index\",\"l1_spell\",\"l1\",\"l1_desc\",\"UID\"]]\n",
    "r4_l1.to_csv(f\"{OUTPUT_DIR}/outcomes_l1.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... ./output/outcomes_l1.csv\")\n",
    "\n",
    "l1_indexes = r4_l1[\"l1_index\"]\n",
    "\n",
    "# reading layer 2\n",
    "r4_l2 =  pd.DataFrame(data=[],columns=[])\n",
    "for l1_index in list(l1_indexes):\n",
    "    filename = get_glob_file(f\"{SHEETS_OUTCOMES_DIR}/{l1_index}*/第2層.csv\")\n",
    "    r4_l2_unit =pd.read_csv(filename,encoding=\"utf_8_sig\") \n",
    "    r4_l2_unit=r4_l2_unit.rename(columns={\"第2層\":\"l2\",\"第2層説明\":\"l2_desc\"})\n",
    "    r4_l2_unit[\"l2_index\"] = l1_index+\"-\"+(r4_l2_unit.index+1).astype(\"str\").str.zfill(2)\n",
    "    r4_l2_unit[\"l1_index\"] = l1_index\n",
    "    r4_l2_unit = r4_l2_unit.loc[:,[\"l1_index\",\"l2\",\"l2_desc\",\"l2_index\",\"UID\"]]\n",
    "    r4_l2=pd.concat([r4_l2,r4_l2_unit])\n",
    "r4_l2.to_csv(f\"{OUTPUT_DIR}/outcomes_l2.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... ./output/outcomes_l2.csv\")\n",
    "\n",
    "# reading layer 3 and 4\n",
    "r4_l3 =  pd.DataFrame(data=[],columns=[])\n",
    "r4_l4 =  pd.DataFrame(data=[],columns=[])\n",
    "for l1_index in l1_indexes:\n",
    "    filename = get_glob_file(f\"{SHEETS_OUTCOMES_DIR}/{l1_index}*/第2から4層.csv\")\n",
    "    r4_l234_unit=pd.read_csv(filename)\n",
    "    r4_l234_unit=r4_l234_unit.rename(columns={\"第2層\":\"l2\",\"第3層\":\"l3\",\"第4層\":\"l4\",\"H28対応項目\":\"H28ID\"})\n",
    "    r4_l234_unit = pd.merge(r4_l234_unit,r4_l2.drop(\"UID\",axis=1),how=\"left\",on=\"l2\")\n",
    "    ids=dataframe_to_grouped_numbers(r4_l234_unit,[\"l2\",\"l3\",\"l4\"])\n",
    "\n",
    "    # reading layer 3\n",
    "    r4_l234_unit[\"l3_index\"]=r4_l234_unit[\"l2_index\"]+\"-\"+ids[\"l3\"].astype(\"str\").str.zfill(2)\n",
    "    r4_l3_unit = r4_l234_unit.loc[:,[\"l2_index\",\"l3\",\"l3_index\",\"l3_UID\"]]\n",
    "    r4_l3_unit = r4_l3_unit.rename(columns={\"l3_UID\":\"UID\"})\n",
    "    r4_l3 = pd.concat([r4_l3,r4_l3_unit.drop_duplicates(subset=[\"l3_index\"])]) \n",
    "\n",
    "    # reading layer 4\n",
    "    r4_l234_unit[\"l4_index\"]=r4_l234_unit[\"l3_index\"]+\"-\"+ids[\"l4\"].astype(\"str\").str.zfill(2)\n",
    "    r4_l4_unit = r4_l234_unit.loc[:,[\"l3_index\",\"l4\",\"l4_index\",\"UID\",\"H28ID\"]]\n",
    "    r4_l4 = pd.concat([r4_l4,r4_l4_unit]) \n",
    "\n",
    "\n",
    "r4_l3.to_csv(f\"{OUTPUT_DIR}/outcomes_l3.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... ./output/outcomes_l3.csv\")\n",
    "\n",
    "table_index = pd.read_csv(f\"{OUTPUT_DIR}/table_index.csv\",encoding=\"utf_8_sig\")\n",
    "def format_table_ref(x:str)->str:\n",
    "    def name_to_label(name:str):\n",
    "        try:\n",
    "            return table_index.set_index(\"表名\").at[name,\"id\"]\n",
    "        except KeyError:\n",
    "            return \"\"\n",
    "\n",
    "    def replace_func(reg:re.match)->str:\n",
    "        name = reg.group(1)\n",
    "        whole = reg.group(0)\n",
    "        label = name_to_label(name)\n",
    "        if label:\n",
    "            return f\"[@tbl:{label}]\"\n",
    "        else:\n",
    "            return whole\n",
    "    return re.sub(r\"表\\[([^\\]]+)\\]\",replace_func,x)\n",
    "\n",
    "\n",
    "r4_l4[\"l4\"] = r4_l4[\"l4\"].map(format_table_ref)\n",
    "\n",
    "r4_l4.to_csv(f\"{OUTPUT_DIR}/outcomes_l4.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... ./output/outcomes_l4.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from lib.utils import BASE_DIR,SHEETS_OUTCOMES_DIR,OUTPUT_DIR\n",
    "\n",
    "def get_glob_file(glob_path:str)->str:\n",
    "    files = glob.glob(glob_path)\n",
    "    if len(files)==0:\n",
    "        raise Exception(f\"Cannot find {glob_path}\")\n",
    "    return list(glob.glob(glob_path))[0]\n",
    "\n",
    "\n",
    "os.makedirs(f\"{OUTPUT_DIR}/tables\", exist_ok=True)\n",
    "\n",
    "r4_l1=pd.read_csv(f\"{OUTPUT_DIR}/outcomes_l1.csv\")\n",
    "df = pd.DataFrame([])\n",
    "for row in r4_l1.itertuples():\n",
    "    filename = get_glob_file(f\"{SHEETS_OUTCOMES_DIR}/{row.l1_index}*/行き先がないID.csv\")\n",
    "    unit = pd.read_csv(filename,encoding=\"utf_8_sig\")\n",
    "    unit[\"l1_index\"]=row.l1_index\n",
    "    df= pd.concat([df,unit.loc[:,[\"H28ID\",\"理由・コメント\",\"l1_index\"]]])\n",
    "\n",
    "df = df.dropna(subset=[\"H28ID\"])    \n",
    "df.to_csv(f\"{OUTPUT_DIR}/deleted_or_moved.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(f\"output... ./output/deleted_or_moved.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from lib.utils import BASE_DIR,SHEETS_GENERAL_DIR,OUTPUT_DIR\n",
    "\n",
    "raw=pd.read_csv(f\"{SHEETS_GENERAL_DIR}/H28/H28.csv\", index_col=0)\n",
    "raw\n",
    "\n",
    "\n",
    "data=pd.DataFrame([])\n",
    "data[\"id1\"]=raw[\"第1層（大項目）\"].str.extract(r\"^(.)\")\n",
    "data[\"text1\"]=raw[\"第1層（大項目）\"].str.extract(r\"^. ?(.+)\")\n",
    "data[\"id2\"]=raw[\"第2層（中項目）\"].str.extract(r\"^.\\-(\\d+)\")\n",
    "data[\"id2\"]=data[\"id1\"]+\"-\"+data[\"id2\"].str.zfill(2)\n",
    "data[\"text2\"]=raw[\"第2層（中項目）\"].str.extract(r\"^.\\-\\d+ (.+)\")\n",
    "data[\"id3\"]=raw[\"第3層（小項目）\"].str.extract(r\"^.\\-\\d+\\-(\\d+)\")\n",
    "data[\"id3\"]=data[\"id2\"]+\"-\"+data[\"id3\"].str.zfill(2)\n",
    "data[\"text3\"]=raw[\"第3層（小項目）\"].str.extract(r\"^.\\-\\d+\\-\\d+\\) (.+)\")\n",
    "raw[\"id3\"]=data[\"id3\"]\n",
    "\n",
    "id4_list=[]\n",
    "text4_list=[]\n",
    "current_parent=\"\"\n",
    "prev_text=\"\"\n",
    "current_index=0\n",
    "for index,row in raw.iterrows():\n",
    "  text=row[\"第4層（細小項目）\"]\n",
    "  parent=row[\"id3\"]\n",
    "  if parent!= current_parent:\n",
    "    current_index=0\n",
    "    prev_text=\"\"\n",
    "  if prev_text!= text:\n",
    "    current_index=current_index+1\n",
    "  current_parent=parent\n",
    "  prev_text=text\n",
    "  if text==\"なし\":\n",
    "    id4_list.append(f\"{parent}-na\")\n",
    "    text4_list.append(text)\n",
    "  else:\n",
    "    id4_list.append(f\"{parent}-{str(current_index).zfill(2)}\")\n",
    "    text4_list.append(re.sub(r\"^.\\-\\d+\\-\\d+\\)\\-\\(\\d+\\) \",\"\",str(text)))\n",
    "\n",
    "data[\"id4\"]=id4_list\n",
    "data[\"text4\"]=text4_list\n",
    "raw[\"id4\"]=data[\"id4\"]\n",
    "\n",
    "id5_list=[]\n",
    "text5_list=[]\n",
    "current_parent=\"\"\n",
    "prev_text=\"\"\n",
    "current_index=0\n",
    "for index,row in raw.iterrows():\n",
    "  text=row[\"第5層（学修目標）\"]\n",
    "  parent=row[\"id4\"]\n",
    "  if parent!= current_parent:\n",
    "    current_index=0\n",
    "    prev_text=\"\"\n",
    "  if prev_text!= text:\n",
    "    current_index=current_index+1\n",
    "  current_parent=parent\n",
    "  prev_text=text\n",
    "  if text==\"なし\":\n",
    "    id5_list.append(f\"{parent}-na\")\n",
    "    text5_list.append(text)\n",
    "  else:\n",
    "    id5_list.append(f\"{parent}-{str(current_index).zfill(2)}\")\n",
    "    item_text=re.sub(r\"^([.０-９0-9]{1,2})( |\\.|．)\",\"\",str(text))\n",
    "    item_text=re.sub(r\"^[①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮⑯⑰⑱⑲⑳㉑㉒㉓㉔㉕㉖]\",\"\",str(item_text))\n",
    "    text5_list.append(item_text)\n",
    "\n",
    "data[\"id5\"]=id5_list\n",
    "data[\"text5\"]=text5_list\n",
    "\n",
    "distdir=f\"{OUTPUT_DIR}/2016\"\n",
    "os.makedirs(distdir,exist_ok=True)\n",
    "data.to_csv(f\"{distdir}/goals.csv\", encoding = \"utf_8_sig\", index=False)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
