{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from lib.utils import BASE_DIR,SHEETS_DIR,SHEETS_OUTCOMES_DIR,OUTCOME_TABLE_SOURCE_DIR\n",
    "\n",
    "os.makedirs( f\"{OUTCOME_TABLE_SOURCE_DIR}\", exist_ok=True)\n",
    "file_list = glob.glob(f\"{SHEETS_OUTCOMES_DIR}/*編集用/別表-*.csv\")\n",
    "for file in file_list:\n",
    "    name = re.search(r\"別表\\-(.+)\\.csv\",file).group(1)\n",
    "    df = pd.read_csv(file,encoding=\"utf_8_sig\")\n",
    "    df.to_csv(f\"{OUTCOME_TABLE_SOURCE_DIR}/{name}.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "    print(f\"output... {OUTCOME_TABLE_SOURCE_DIR}/{name}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from lib.utils import BASE_DIR,SHEETS_GENERAL_DIR,SHEETS_OUTCOMES_DIR,OUTPUT_DIR,OUTCOME_TABLE_SOURCE_DIR,TABLE_FORMATTED_DIR\n",
    "from lib.apply_condition_to_dataframe  import apply_condition_to_dataframe\n",
    "\n",
    "os.makedirs(OUTPUT_DIR,exist_ok=True)\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{SHEETS_GENERAL_DIR}/略語集/略語.csv\",encoding=\"utf_8_sig\")\n",
    "df.to_csv(f\"{OUTPUT_DIR}/definitions.csv\",encoding=\"utf_8_sig\",index=False)\n",
    "print(f\"output... definitions.csv\")\n",
    "\n",
    "df = pd.read_csv(f\"{SHEETS_OUTCOMES_DIR}/別表一覧/別表一覧.csv\",encoding=\"utf_8_sig\")\n",
    "df.to_csv(f\"{OUTPUT_DIR}/table_index.csv\",encoding=\"utf_8_sig\",index=False)\n",
    "print(f\"output... table_index.csv\")\n",
    "\n",
    "\n",
    "os.makedirs(TABLE_FORMATTED_DIR,exist_ok=True)\n",
    "for row in df.itertuples():\n",
    "    source = pd.read_csv(f\"{OUTCOME_TABLE_SOURCE_DIR}/{row.データ元}.csv\")\n",
    "    source = apply_condition_to_dataframe(source,row.条件)\n",
    "    source[\"id\"]=source.reset_index().index+1\n",
    "    source[\"id\"]=f\"TBL-{row.id}-\"+source[\"id\"].astype(str).str.zfill(3)\n",
    "    source = source.loc[:,[*re.split(r\" *, *\",row.列),\"id\",\"UID\",\"H28対応項目\"] ]\n",
    "    source.to_csv(f\"{TABLE_FORMATTED_DIR}/{row.id}.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from lib.utils import BASE_DIR,SHEETS_OUTCOMES_DIR,OUTPUT_DIR\n",
    "from lib.dataframe_to_grouped_numbers import dataframe_to_grouped_numbers\n",
    "\n",
    "table_index = pd.read_csv(f\"{OUTPUT_DIR}/table_index.csv\",encoding=\"utf_8_sig\")\n",
    "r4_l1=pd.read_csv(f\"{SHEETS_OUTCOMES_DIR}/第1層/第1層.csv\")\n",
    "\n",
    "os.makedirs(f\"{OUTPUT_DIR}\",exist_ok=True)\n",
    "\n",
    "r4_l1=r4_l1.rename(columns={\"第1層イニシャル\":\"id\",\"第1層フルスペル\":\"spell\",\"第1層\":\"l1\",\"第1層説明\":\"l1_desc\"})\n",
    "r4_l1=r4_l1.loc[:,[\"id\",\"spell\",\"l1\",\"l1_desc\",\"UID\"]]\n",
    "r4_l1.to_csv(f\"{OUTPUT_DIR}/outcomes_l1.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... ./output/outcomes_l1.csv\")\n",
    "\n",
    "r4_l1 = r4_l1.rename(columns={\"UID\":\"l1_UID\",\"id\":\"l1_id\"})\n",
    "\n",
    "\n",
    "columns=[\"l1\",\"l2\",\"l2_desc\",\"l3\",\"l4\",\"UID\",\"H28ID\",\"l2_UID\"]\n",
    "r4_l234 = pd.DataFrame(data=[],columns=columns)\n",
    "r4_l2 =  pd.DataFrame(data=[],columns=[])\n",
    "for index, row in r4_l1.iterrows():\n",
    "    r4_l34_unit=pd.read_csv(f\"{SHEETS_OUTCOMES_DIR}/{row.l1_id}-{row.l1}編集用/第2から4層.csv\")\n",
    "    r4_l34_unit=r4_l34_unit.rename(columns={\"第2層\":\"l2\",\"第3層\":\"l3\",\"第4層\":\"l4\",\"H28対応項目\":\"H28ID\"})\n",
    "    r4_l2_unit=pd.read_csv(f\"{SHEETS_OUTCOMES_DIR}/{row.l1_id}-{row.l1}編集用/第2層.csv\")\n",
    "    r4_l2_unit=r4_l2_unit.rename(columns={\"第2層\":\"l2\",\"第2層説明\":\"l2_desc\"})\n",
    "    r4_l2_unit=r4_l2_unit.rename(columns={\"UID\":\"l2_UID\"})\n",
    "    r4_l2 = pd.concat([r4_l2,r4_l2_unit])\n",
    "    r4_l34_unit[\"l1\"] = row.l1\n",
    "    r4_l34_unit = pd.merge(r4_l34_unit,r4_l2_unit,how=\"left\",on=\"l2\")\n",
    "    r4_l234=pd.concat([r4_l234,r4_l34_unit.loc[:,columns]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "r4=pd.merge(r4_l1,r4_l234,how=\"outer\",on=\"l1\")\n",
    "layers = [\"l1\",\"l2\",\"l3\",\"l4\"]\n",
    "r4=r4.dropna(subset=layers).reset_index()\n",
    "ids=dataframe_to_grouped_numbers(r4,layers)\n",
    "ids[\"l1_id\"] = r4[\"l1_id\"]\n",
    "ids[\"l2_id\"]=ids[\"l1_id\"]+\"-\"+ids[\"l2\"].astype('str').str.zfill(2)\n",
    "ids[\"l3_id\"]=ids[\"l2_id\"]+\"-\"+ids[\"l3\"].astype('str').str.zfill(2)\n",
    "ids[\"l4_id\"]=ids[\"l3_id\"]+\"-\"+ids[\"l4\"].astype('str').str.zfill(2)\n",
    "ids = ids.loc[:,[\"l1_id\",\"l2_id\",\"l3_id\",\"l4_id\"]]\n",
    "r4[\"id\"] =  ids[\"l4_id\"] \n",
    "r4 = pd.concat([r4,ids],axis=1)\n",
    "\n",
    "r4_l2 = r4.loc[:,[\"l2_id\",\"l2\",\"l2_desc\",\"l2_UID\"]].drop_duplicates(subset=\"l2_id\")\n",
    "r4_l2 = r4_l2.rename(columns={\"l2_id\":\"id\",\"l2_UID\":\"UID\"})\n",
    "r4_l2.to_csv(f\"{OUTPUT_DIR}/outcomes_l2.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... ./output/outcomes_l2.csv\")\n",
    "\n",
    "\n",
    "def format_table_ref(x:str)->str:\n",
    "    def name_to_label(name:str):\n",
    "        try:\n",
    "            return table_index.set_index(\"表名\").at[name,\"id\"]\n",
    "        except KeyError:\n",
    "            return \"\"\n",
    "\n",
    "    def replace_func(reg:re.match)->str:\n",
    "        name = reg.group(1)\n",
    "        whole = reg.group(0)\n",
    "        label = name_to_label(name)\n",
    "        if label:\n",
    "            return f\"[@tbl:{label}]\"\n",
    "        else:\n",
    "            return whole\n",
    "    return re.sub(r\"表\\[([^\\]]+)\\]\",replace_func,x)\n",
    "\n",
    "\n",
    "r4[\"l4\"] = r4[\"l4\"].map(format_table_ref)\n",
    "\n",
    "\n",
    "r4=r4.loc[:,[\"l1\",\"l2\",\"l3\",\"l4\",\"id\",\"UID\",\"H28ID\",\"l1_UID\",\"l2_UID\",\"l1_id\",\"l2_id\",\"l3_id\",\"l4_id\"]]\n",
    "\n",
    "r4.to_csv(f\"{OUTPUT_DIR}/outcomes.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(\"output... outcomes.csv\")\n",
    "\n",
    "r4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from lib.utils import BASE_DIR,SHEETS_OUTCOMES_DIR,OUTPUT_DIR\n",
    "\n",
    "\n",
    "r4_l1=pd.read_csv(f\"{OUTPUT_DIR}/outcomes.csv\")\n",
    "os.makedirs(f\"{OUTPUT_DIR}/tables\", exist_ok=True)\n",
    "file_list = glob.glob(f\"{SHEETS_OUTCOMES_DIR}/*編集用/行き先がないID.csv\")\n",
    "df = pd.DataFrame([],columns=[])\n",
    "for file in file_list:\n",
    "    name = re.search(r\"([^\\\\\\/\\\\-]+)\\-[^\\\\\\/]+編集用\",file).group(1)\n",
    "    unit = pd.read_csv(file,encoding=\"utf_8_sig\")\n",
    "    print(name)\n",
    "    unit[\"id\"]=name\n",
    "    df= pd.concat([df,unit])\n",
    "\n",
    "df=pd.merge(df,r4_l1,how=\"left\",on=\"id\")\n",
    "df.to_csv(f\"{OUTPUT_DIR}/deleted_or_moved.csv\",encoding=\"utf_8_sig\",quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "print(f\"output... ./output/deleted_or_moved.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from lib.utils import BASE_DIR,SHEETS_GENERAL_DIR,OUTPUT_DIR\n",
    "\n",
    "raw=pd.read_csv(f\"{SHEETS_GENERAL_DIR}/H28/H28.csv\", index_col=0)\n",
    "raw\n",
    "\n",
    "\n",
    "data=pd.DataFrame([])\n",
    "data[\"id1\"]=raw[\"第1層（大項目）\"].str.extract(r\"^(.)\")\n",
    "data[\"text1\"]=raw[\"第1層（大項目）\"].str.extract(r\"^. ?(.+)\")\n",
    "data[\"id2\"]=raw[\"第2層（中項目）\"].str.extract(r\"^.\\-(\\d+)\")\n",
    "data[\"id2\"]=data[\"id1\"]+\"-\"+data[\"id2\"].str.zfill(2)\n",
    "data[\"text2\"]=raw[\"第2層（中項目）\"].str.extract(r\"^.\\-\\d+ (.+)\")\n",
    "data[\"id3\"]=raw[\"第3層（小項目）\"].str.extract(r\"^.\\-\\d+\\-(\\d+)\")\n",
    "data[\"id3\"]=data[\"id2\"]+\"-\"+data[\"id3\"].str.zfill(2)\n",
    "data[\"text3\"]=raw[\"第3層（小項目）\"].str.extract(r\"^.\\-\\d+\\-\\d+\\) (.+)\")\n",
    "raw[\"id3\"]=data[\"id3\"]\n",
    "\n",
    "id4_list=[]\n",
    "text4_list=[]\n",
    "current_parent=\"\"\n",
    "prev_text=\"\"\n",
    "current_index=0\n",
    "for index,row in raw.iterrows():\n",
    "  text=row[\"第4層（細小項目）\"]\n",
    "  parent=row[\"id3\"]\n",
    "  if parent!= current_parent:\n",
    "    current_index=0\n",
    "    prev_text=\"\"\n",
    "  if prev_text!= text:\n",
    "    current_index=current_index+1\n",
    "  current_parent=parent\n",
    "  prev_text=text\n",
    "  if text==\"なし\":\n",
    "    id4_list.append(f\"{parent}-na\")\n",
    "    text4_list.append(text)\n",
    "  else:\n",
    "    id4_list.append(f\"{parent}-{str(current_index).zfill(2)}\")\n",
    "    text4_list.append(re.sub(r\"^.\\-\\d+\\-\\d+\\)\\-\\(\\d+\\) \",\"\",str(text)))\n",
    "\n",
    "data[\"id4\"]=id4_list\n",
    "data[\"text4\"]=text4_list\n",
    "raw[\"id4\"]=data[\"id4\"]\n",
    "\n",
    "id5_list=[]\n",
    "text5_list=[]\n",
    "current_parent=\"\"\n",
    "prev_text=\"\"\n",
    "current_index=0\n",
    "for index,row in raw.iterrows():\n",
    "  text=row[\"第5層（学修目標）\"]\n",
    "  parent=row[\"id4\"]\n",
    "  if parent!= current_parent:\n",
    "    current_index=0\n",
    "    prev_text=\"\"\n",
    "  if prev_text!= text:\n",
    "    current_index=current_index+1\n",
    "  current_parent=parent\n",
    "  prev_text=text\n",
    "  if text==\"なし\":\n",
    "    id5_list.append(f\"{parent}-na\")\n",
    "    text5_list.append(text)\n",
    "  else:\n",
    "    id5_list.append(f\"{parent}-{str(current_index).zfill(2)}\")\n",
    "    item_text=re.sub(r\"^([.０-９0-9]{1,2})( |\\.|．)\",\"\",str(text))\n",
    "    item_text=re.sub(r\"^[①②③④⑤⑥⑦⑧⑨⑩⑪⑫⑬⑭⑮⑯⑰⑱⑲⑳㉑㉒㉓㉔㉕㉖]\",\"\",str(item_text))\n",
    "    text5_list.append(item_text)\n",
    "\n",
    "data[\"id5\"]=id5_list\n",
    "data[\"text5\"]=text5_list\n",
    "\n",
    "distdir=f\"{OUTPUT_DIR}/2016\"\n",
    "os.makedirs(distdir,exist_ok=True)\n",
    "data.to_csv(f\"{distdir}/goals.csv\", encoding = \"utf_8_sig\", index=False)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
